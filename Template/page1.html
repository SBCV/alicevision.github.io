
<!DOCTYPE html>
<html lang="fr">    
    <head>
        <!-- encodage de la page -->
        <meta charset="utf-8"/>
        <!-- petite déscription du site pour les robots google .... -->
        <meta name="description" content="description de la page"/>
        <!-- balise meta keywords permettant un bon référencement naturel supplémentaire -->
        <meta name="keywords" content="mots-clé1, mots-clé2, ..."/>

        <!-- attribution d'un titre à la page internet -->
        <title>Alice Vision</title>
        <!-- appel de la feuille de style pour la page index.php-->
        <link rel="stylesheet" href="../Design/css/global.css"/>
        <link rel="stylesheet" href="../Design/css/step.css"/>
        <link rel="stylesheet" href="../Design/css/algoPage.css"/>

       <!-- <link rel="stylesheet" href="Design/css/jquery.ui.css"/>
        <link rel="stylesheet" href="Design/css/jquery.ui.html4.css"/>-->
        <link rel="shortcut icon" type="image/x-icon" href="../Design/img/icon.png" />
       <!-- <link rel="stylesheet" href="http://fonts.googleapis.com/css?family=Monsieur+La+Doulaise|Rouge+Script|Tangerine"/>-->
        <script type="text/javascript" src="../Design/js/jquery-1.11.1.min.js"></script>
        <link href="https://fonts.googleapis.com/css?family=Ubuntu:300,300i,400,400i,500,500i,700,700i" rel="stylesheet"> 
    </head>
    <body>
        <div id="borderTop"></div>
        <div id="header">
            <div id="menuMobile">
                <div></div>
                <div>
                    <ul>
                        <li><a href="../index.html">Home</a></li>
                        <li><a href="page1.html">Photogrammetry</a></li>
                        <li><a href="projet.html">Softwares</a></li>
                        <li><a href="libraries.html">Libraries</a></li>
                        <li><a href="about.html">About Us</a></li>
                    </ul>
                </div>
            </div>
            <a href="../index.html"><img id="logoTop" src="../Design/img/logo2.png"/></a>
            <div id="menu">
                <ul>
                    <li><a href="../index.html">Home</a></li>
                    <li><a href="page1.html">Photogrammetry</a></li>
                    <li><a href="projet.html">Softwares</a></li>
                    <li><a href="libraries.html">Libraries</a></li>
                    <li><a href="about.html">About Us</a></li>

                </ul>
            </div>
            <div class="clear"></div>
            <div id="hamburgerMenu" class="">
                <div></div>
                <div>
                    <ul>
                        <li><a href="../index.html">Home</a></li>
                        <li><a href="page1.html">Photogrammetry</a></li>
                        <li><a href="projet.html">Project</a></li>
                        <li><a href="">About Us</a></li>
                        <li><a href="https://openmvg.readthedocs.io/en/latest/">Docs</a></li>
                    </ul>
                </div>
            </div>
            <div id="stepTop">
                <div class="stepLineMini">
                    <div class="step1" id="step1Mini"><p>1</p></div>
                    <div class="l1"></div>
                    <div class="l1b" id="l1bMini"></div>
                    <div class="step2" id="step2Mini"><p>2</p></div>
                    <div class="l2"></div>
                    <div class="l2b" id="l2bMini"></div>
                    <div class="step3" id="step3Mini"><p>3</p></div>
                    <div class="l3"></div>
                    <div class="l3b" id="l3bMini"></div>
                    <div class="step4" id="step4Mini"><p>4</p></div>
                    <div class="l4"></div>
                    <div class="l4b" id="l4bMini"></div>
                    <div class="step5" id="step5Mini"><p>5</p></div>
                    <div class="l5"></div>
                    <div class="l5b" id="l5bMini"></div>
                    <div class="step6" id="step6Mini"><p>6</p></div>
                    <div class="l6"></div>
                    <div class="l6b" id="l6bMini"></div>
                    <div class="step7" id="step7Mini"><p>7</p></div>
                    <div class="l7"></div>
                    <div class="l7b" id="l7bMini"></div>
                    <div class="step8" id="step8Mini"><p>8</p></div>
                </div>
            </div>
            
        </div>
        <div id="content">
            
            
            <div id="stepDiv">

                <h1>Discover stage by stage the functioning of Alice Vision</h1>
                <div class="stepLine">
                    <div class="step1" id="step1"><p>1</p></div>
                    <div class="l1"></div>
                    <div class="l1b" id="l1b"></div>
                    <div class="step2" id="step2"><p>2</p></div>
                    <div class="l2"></div>
                    <div class="l2b" id="l2b"></div>
                    <div class="step3" id="step3"><p>3</p></div>
                    <div class="l3"></div>
                    <div class="l3b" id="l3b"></div>
                    <div class="step4" id="step4"><p>4</p></div>
                    <div class="l4"></div>
                    <div class="l4b" id="l4b"></div>
                    <div class="step5" id="step5"><p>5</p></div>
                    <div class="l5"></div>
                    <div class="l5b" id="l5b"></div>
                    <div class="step6" id="step6"><p>6</p></div>
                    <div class="l6"></div>
                    <div class="l6b" id="l6b"></div>
                    <div class="step7" id="step7"><p>7</p></div>
                    <div class="l7"></div>
                    <div class="l7b" id="l7b"></div>
                    <div class="step8" id="step8"><p>8</p></div>
                </div>
                <div id="stepForMobile">
                    <div ><p><a >1</a></p></div>
                    <div ><p><a >2</a></p></div>
                    <div ><p><a >3</a></p></div>
                    <div ><p><a >4</a></p></div>
                    <div ><p><a >5</a></p></div>
                    <div ><p><a >6</a></p></div>
                    <div ><p><a >7</a></p></div>
                    <div ><p><a >8</a></p></div>
                </div>

            </div>
            <div class = "generalStep">
                <div>
                    <h1>Structure From Motion</h1>
                    <h2>Step 1</h2>
                    <h3> Objectives</h3>
                    <p> Extract 2D points of interest from input images, in order to get image keypoints, corresponding to salient 3D points. Use a binary image mask to only extract features in a subpart of the image.</p>
                </div>
                <div>
                    <h4>Inputs :</h4>
                    <p>Images</p>
                    <br/>
                    <h4>Outputs : </h4>
                    <p>2D points of interest for each images</p>
                </div>
            <div class="clear"></div>
            </div>
            <div class="videoPresentation">
                <div>
                   <iframe width="560" height="315" src="https://www.youtube.com/embed/O-IZz1n4F4g" frameborder="0" allowfullscreen></iframe>

                </div>
                <h3>Resume and comments : </h3>
                <p> This video explain how to find points of interest in all the images that are irrespective of rotation, translation, and scale.</p>
            </div>
            <div class="generalPrincipe">

                <div id='gp1'>
                    <h1>General Principle</h1>
                    <h4> Step 1 : Features Detector</h4>
                    <p> Find points of interest in all the images that are irrespective of rotation, translation, and scale.</p>
                    <h4> Step 2 : Filtering</h4>
                    <p> Selection of the most high-level features while also ensuring repartition in the image.</p>
                    <h4> Step 3 : Descriptor Extractor</h4>
                    <p> Generate a descriptor to stock these data as numerical features.</p><h4> Optional Step : Masking Optimization</h4>
                    <p> Use a binary image mask to only extract features in a subpart of the image.</p>

                </div>
                <div id="gp2">
                    <img src="../Design/img/step_img/img_step1b.png">
                </div>
            
                    
            </div>
                <!--<div>
                    
                    <div class="gp1">
                        <img src="../Design/img/step_img/img_step1.png">
                        
                    </div>
                    <div class="gp2">
                        
                        <h4>Etapes</h4>
                         <p>
                         <strong>Feature :</strong> Déterminer les positions de ces points caractéristiques. 
                         <br/><br/>
                        <strong> Descriptor : </strong> et leur associé un descripteur afin d’identifier ce point.
                        <br/><br/>
                        Plusieurs types de points caractéristiques. Trouver des points invariants en fonction de l’échelle, du point de vue, changement d’éclairage, de luminosité, du bruit de la caméra.</p>
                    </div>-->

            <div class ="allAlgo">
                
                    <div id="algo">
                        
                        <div class = "implementedAlgo" id="implementedAlgo">
                            <h1>The algorithm</h1>
                            <h2>Implemented algorithm</h2>
                            <div id="algoImplemented1">
                                <h3>SIFT (Scale Invariant Feature Transform)</h3>
                                <h4>1- Scale-space Extrema Detection</h4><h4></h4>
                                <p>The initial goal of SIFT is to extract discriminative patches in a first image that can be compared to discriminative patches of a second image irrespective of rotation, translation, and scale. As a relevant detail only exists at a certain scale, the extracted patches are centered at stable points of interest which are well-known to lie at extrema of some specific image energy-based representation ---so-called Laplacian--- in the image scale-space representation. The key idea is that, to some extent, one can use the SIFT invariance to deal with the image transformations occurring when the viewpoints are changing during image acquisition.<br/><br/>From the representation of one image at different scales, which is technically done by computing a pyramid of downscaled images at different scales, SIFT computes scale-space maxima of the Laplacian representation, which is a specific image energy-based representation, of the image, using so-called differences of Gaussians.</p>
                                <img src="../Design/img/step_img/step4Algo1img1.jpg">
                                <p>Once this DoG are found, images are searched for local extrema over scale and space. For eg, one pixel in an image is compared with its 8 neighbours as well as 9 pixels in next scale and 9 pixels in previous scales. If it is a local extrema, it is a potential keypoint. It basically means that keypoint is best represented in that scale.</p><p></p>
                                <img src="../Design/img/step_img/step4Algo1img2.jpg">
                                <h4>2- Keypoint Localization</h4><h4></h4>
                                <p>Once potential keypoints locations are found, they have to be refined to get more accurate results. They used Taylor series expansion of scale space to get more accurate location of extrema, and if the intensity at this extrema is less than a threshold value (0.03 as per the paper), it is rejected. DoG has higher response for edges, so edges also need to be removed. For this, a concept similar to Harris corner detector is used. So it eliminates any low-contrast keypoints and edge keypoints and what remains is strong interest points.</p><p></p>
                                <h4>3- Orientation Assignment</h4><h4></h4>
                                <p>Now an orientation is assigned to each keypoint to achieve invariance to image rotation. A neighbourhood is taken around the keypoint location depending on the scale, and the gradient magnitude and direction is calculated in that region. An orientation histogram with 36 bins covering 360 degrees is created. (It is weighted by gradient magnitude and gaussian-weighted circular window with σ equal to 1.5 times the scale of keypoint. The highest peak in the histogram is taken and any peak above 80% of it is also considered to calculate the orientation. It creates keypoints with same location and scale, but different directions. It contribute to stability of matching.</p><p></p>
                                <h4>4- Keypoint Descriptor</h4><h4></h4>
                                <p>Now an orientation is assigned to each keypoint to achieve invariance to image rotation. A neighbourhood is taken around the keypoint location depending on the scale, and the gradient magnitude and direction is calculated in that region. An orientation histogram with 36 bins covering 360 degrees is created. (It is weighted by gradient magnitude and gaussian-weighted circular window with σ equal to 1.5 times the scale of keypoint. The highest peak in the histogram is taken and any peak above 80% of it is also considered to calculate the orientation. It creates keypoints with same location and scale, but different directions. It contribute to stability of matching.</p><p></p>
                                <p><a href="http://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html">For more informations</a></p><p></p></div>
                                <p class="seeMore" id="seeMore1" ><a>See more</a></p><div id="algoImplemented2"><h3>AKAZE</h3><h3></h3><h4>1- Computation of the Nonlinear Scale Space</h4><h4></h4><p> Similar approach as done in SIFT, discretizing the scale space in logarithmic steps arranged in a series of O octaves and S sub-levels. Note that we always work with the original image resolution, without performing any downsampling at each new octave as done in SIFT. The set of octaves and sub-levels are identified by a discrete octave index o and a sub-level one s. Given an input image, we firstly convolve the image with a Gaussian kernel to reduce noise and possible image artefacts. From that base image we compute the image gradient histogram and obtain a contrast parameter. </p><p></p><img src="../Design/img/step_img/step4Algo2img1.png"><p>fig :  Comparison between the Gaussian and nonlinear diffusion scale space for several evolution times ti. First Row: Gaussian scale space (linear diffusion). The scale space is formed by convolving the original image with a Gaussian kernel of increasing standard deviation. Second Row: Nonlinear diffusion scale space with conductivity function g3. </p><p></p><p>Then, given the contrast parameter and the set of evolution times ti, it is straightforward to build the nonlinear scale space.As it can be observed, Gaussian blurring smoothes for equal all the structures in the image, whereas in the nonlinear scale space strong image edges remain unaffected</p><p></p><h4>2- Feature Detection</h4><h4></h4><p>For detecting points of interest, we compute the response of scale-normalized determinant of the Hessian at multiple scale levels. Given the set of filtered images from the nonlinear scale space, we analyze the detector response at different scale levels. We search for maxima in scale and spatial location. The search for extrema is performed in all the filtered images. For speeding-up the search for extrema, we firstly check the responses over a window of size 3×3 pixels, in order to discard quickly non-maxima responses. Finally, the position of the keypoint is estimated with sub-pixel accuracy. The set of first and second order derivatives are approximated by means of 3 × 3 Scharr filters of different derivative step sizes. Second order derivatives are approximated by using consecutive Scharr filters in the desired coordinates of the derivatives</p><p></p><p>These filters approximate rotation invariance significantly better than other popular filters such as Sobel filters or standard central differences differentiation. Notice here that although we need to compute multiscale derivatives for every pixel, we save computational efforts in the description step, since we re-use the same set of derivatives that are computed in the detection step.</p><p></p><h4>3-Feature Description</h4><h4></h4><p><strong>3.1- Finding the Dominant Orientation</strong></p><p></p><p>For obtaining rotation invariant descriptors, it is necessary to estimate the dominant orientation in a local neighbourhood centered at the keypoint location. Similar to SURF, we find the dominant orientation in a circular area with a sampling step of size. For each of the samples in the circular area, first order derivatives are weighted with a Gaussian centered at the interest point. Then, the derivative responses are represented as points in vector space and the dominant orientation is found by summing the responses within a sliding circle segment covering an angle of π/3. From the longest vector the dominant orientation is obtained.</p><p></p><p><strong>3.2- Building the Descriptor</strong></p><p></p><p>We use the M-SURF descriptor adapted to our nonlinear scale space framework. For a detected feature at a certain scale, first order derivatives are computed over a rectangular grid. This grid is divided into 4×4 subregions. The derivative responses in each subregion are weighted with a Gaussian centered on the subregion center and summed into a descriptor vector. Then, each subregion vector is weighted using a Gaussian defined over a mask of 4×4 and centered on the interest keypoint. When considering the dominant orientation of the keypoint, each of the samples in the rectangular grid is rotated according to the dominant orientation. In addition, the derivatives are also computed according to the dominant orientation. Finally, the descriptor vector of length 64 is normalized into a unit vector to achieve invariance to contrast.</p><p></p><p><a href="http://docs.opencv.org/trunk/da/df5/tutorial_py_sift_intro.html">For more informations</a></p><p></p></div><p class="seeMore" id="seeMore2" >See more</a></p></div>
                        <div class="existantAlgo">
                            <h1>The algorithm</h1>
                            <h2>Other algorithms</h2>
                            <div id="algoExisted1"><h3>Feature Detector</h3><ul><li>SIFT</li><li>ORB</li><li>undefined</li><li>BRISK</li><li>MSER</li><li>GFTT – GoodFeaturesToTrackDetector</li><li>HARRIS – GoodFeaturesToTrackDetector with Harris detector enabled</li><li>Dense – DenseFeatureDetector</li><li>SimpleBlob – SimpleBlobDetector</li></ul></div><div id="algoExisted2"><h3>Feature Detector</h3><ul><li>SURF</li><li>SURF</li><li>BRIEF – BriefDescriptorExtractor</li><li>BRISK </li><li>ORB</li><li>FREA</li><li>MOPS - Multiscale Oriented PatcheS descriptor</li></ul></div></div>
                        
                    </div>
                    <div class="clear"></div>  
                </div>

                <div id = "biblio">
                        <h1>Bibliographie</h1>
                        <div>
                            <h6>[Kneip] </h6>
                            <p>A Novel Parametrization of the P3P-Problem for a Direct Computation of Absolute Camera Position and Orientation. Kneip, L.; Scaramuzza, D. ; Siegwart, R. CVPR 2011<br>Accurate O(n) Solution to the PnP Problem. V. Lepetit and F. Moreno-Noguer and P. Fua,</p>
                        </div>
                        <div>
                            <h6>[EPnP]  </h6>
                            <p>EPnP: An Accurate O(n) Solution to the PnP Problem. V. Lepetit and F. Moreno-Noguer and P. Fua, IJCV 2009. vol. 81, no. 2.</p>
                        </div>
                        <div>
                            <h6>[DSplom] </h6>
                            <p>A Novel Parametrization of the P3P-Problem for a Direct Computation of Absolute Camera Position and Orientation. Kneip, L.; Scaramuzza, D. ; Siegwart, R. CVPR 2011<br>Accurate O(n) Solution to the PnP Problem. V. Lepetit and F. Moreno-Noguer and P. Fua,</p>
                        </div>
                        
                    </div>
                    <div class="pagination">
                        <button id="prevBtn"><a href="#stepDiv">Previous</a></button>
                        <button id="nextBtn"><a href="#stepDiv"> Next</a></button>

                    </div>
                    <div class="clear"></div>

            </div>

        </div>
        <div id="footer">
           <!-- <div>
                <img src="../Design/img/logoNoir.png"/>
                <p><!--Alice vision build a fully integrated software for 3D reconstruction, photomodeling and camera tracking. We aim to provide a strong software basis with state-of-the-art computer vision algorithms that can be tested, analyzed and reused.<p>
            </div>-->
            <div id="informations">
                <div>
                    <h2>Informations</h2>
                    <a href="mailto:alicevision@googlegroups.com">Contact Us</a>  
                    <a href="about.html">About Us</a>
                    <a href="history.html">History</a>
                </div>
                <div>
                    <h2>Alice Vision</h2>
                    <a href="https://openmvg.readthedocs.io/en/latest/"> Documentation</a>
                    <a href="page1.html">Step by Step</a>              
                </div>

                <div>
                    <h2>Softwares</h2>
                    <a href="https://www.autodesk.fr/products/maya/overview"> Maya MVG</a>
                    <a href="http://meshroom.com/">Meshroom</a>   
                    <a href="http://www.openfx.org/">OfxMVG</a>   
                </div>
                <div id="partenaire">
                    <h2>Partner</h2>
                    <a href="http://www.mikrosimage.com/"><img src="../Design/img/partenaire1.png"/></a>
                    <a href="https://www.cvut.cz/en "><img src="../Design/img/partenaire2.png"/></a>
                    <a href="https://www.simula.no/"><img src="../Design/img/partenaire3.png"/></a>
                    <a href="http://www.inp-toulouse.fr/fr/index.html"><img src="../Design/img/partenaire4.png"/></a>
                </div>
                
            </div>
            <div class="clear"></div>

        </div>
        
        <div id="copyRight"><p> Copyright © 2017 - Alice Vision - All rights reserved</p></div>
        <div id="borderBottom"></div>


        <script src="../Design/js/mainJs.js"></script>
        <script src="../Design/js/mainJquery.js"></script>
        <script src="../Design/js/steps.js"></script>
        <script src="../Design/js/utilisationjson.js"></script>
        <script type="text/javascript" src="../Design/js/jquery-ui-1.8.20.custom.min.js"></script>
       <!-- <script type="text/javascript" src="Design/js/modernizr.2.5.3.min.js"></script>-->
    </body>
</html>